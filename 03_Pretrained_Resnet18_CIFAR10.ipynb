{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9ca284",
   "metadata": {},
   "source": [
    "### Import Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9a3604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8557de",
   "metadata": {},
   "source": [
    "### Download CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c41abe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root = './data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.CIFAR10(\n",
    "    root = './data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e1414b",
   "metadata": {},
   "source": [
    "### Visualize CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5135460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "img, label = train_data[sample_idx]\n",
    "imshow(torchvision.utils.make_grid(img))\n",
    "print(f'{classes[label]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af577830",
   "metadata": {},
   "source": [
    "### Split the training dataset into training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7a6680e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# your code here\n",
    "train_data, val_data = train_test_split(train_data, test_size = 0.1, random_state = 123, shuffle = True)\n",
    "print(train_data[0][0].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c47cff3",
   "metadata": {},
   "source": [
    "### Prepare for the datasets using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97748f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    'val'  : torch.utils.data.DataLoader(val_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=1),\n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d16e0f",
   "metadata": {},
   "source": [
    "### Import nn module and pre-trained resent18 from torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee0eec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce0003c",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1681ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters before building the model\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "num_epochs = 5 #너무 오래걸려서 epoch 5가 나을듯.\n",
    "learning_rate = 0.01 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab6dba",
   "metadata": {},
   "source": [
    "### Build a pretrained ResNet with FC layer for image classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28dfcba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resnet18(\n",
      "  (rnet): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "class Resnet18(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # your code here\n",
    "        self.rnet = models.resnet18(weights=True)\n",
    "        ftrs = self.rnet.fc.in_features\n",
    "        self.rnet.fc = nn.Linear(ftrs , num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # your code here\n",
    "        x = self.rnet(x)\n",
    "        return x# your code here\n",
    "    \n",
    "\n",
    "model = Resnet18(num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d3acaf",
   "metadata": {},
   "source": [
    "### Set a loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9029a54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()  # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571461b",
   "metadata": {},
   "source": [
    "### Set an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d359e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)   # your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f7f51",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45844c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss =  tensor(859.0302, grad_fn=<AddBackward0>)\n",
      "tensor(0.3340)\n",
      "total_loss =  tensor(696.6605, grad_fn=<AddBackward0>)\n",
      "tensor(0.4866)\n",
      "total_loss =  tensor(568.1426, grad_fn=<AddBackward0>)\n",
      "tensor(0.5648)\n",
      "total_loss =  tensor(488.4698, grad_fn=<AddBackward0>)\n",
      "tensor(0.6104)\n",
      "total_loss =  tensor(426.9862, grad_fn=<AddBackward0>)\n",
      "tensor(0.6562)\n",
      "total_loss =  tensor(382.0360, grad_fn=<AddBackward0>)\n",
      "tensor(0.6784)\n",
      "total_loss =  tensor(343.9857, grad_fn=<AddBackward0>)\n",
      "tensor(0.6944)\n",
      "total_loss =  tensor(314.5210, grad_fn=<AddBackward0>)\n",
      "tensor(0.7064)\n",
      "total_loss =  tensor(281.3339, grad_fn=<AddBackward0>)\n",
      "tensor(0.7048)\n",
      "total_loss =  tensor(254.6227, grad_fn=<AddBackward0>)\n",
      "tensor(0.7132)\n"
     ]
    }
   ],
   "source": [
    "def train(num_epochs, model, loaders):\n",
    "        \n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model\n",
    "        # your code here\n",
    "        total_loss = 0.0\n",
    "        for image, label in loaders['train']:\n",
    "            #print(1)\n",
    "            output = model(image)\n",
    "            #label = label.to(device) #GPU 있으면 필요있는 코드?\n",
    "            loss = loss_func(output, label)\n",
    "            total_loss += loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"total_loss = \", total_loss)\n",
    "\n",
    "                \n",
    "        # Validate the model\n",
    "        # your code here\n",
    "        with torch.no_grad():\n",
    "            total_right = 0\n",
    "            for image, label in loaders['val']:\n",
    "                output = model(image)\n",
    "                #label = label.to(device)\n",
    "                right = (output.max(1)[1] == label).sum()\n",
    "                total_right += right\n",
    "            print(total_right / len(loaders['val'].dataset))\n",
    "        \n",
    "\n",
    "train(num_epochs, model, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d04219",
   "metadata": {},
   "source": [
    "### Evaluate the trained model (compute accuracy on the test dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9bb0d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average accuracy : 0.7229999899864197\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# your code here\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_right = 0\n",
    "    for image, label in loaders['test']:\n",
    "        output = model(image)\n",
    "        label = label.to(device)\n",
    "        right = (output.max(1)[1] == label).sum()\n",
    "        total_right += right\n",
    "    print(f\"average accuracy : {total_right/len(loaders['test'].dataset)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d53c7a",
   "metadata": {},
   "source": [
    "### Show the results with randomly selected 10 samples from the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "363b77b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number: [5 8 0 0 6 5 5 2 5 1]\n",
      "Actual number:    [3 8 8 0 6 6 1 6 3 1]\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(loaders['test']))\n",
    "imgs, lbls = sample\n",
    "imgs = imgs\n",
    "lbls = lbls\n",
    "test_output = model(imgs[:10])\n",
    "predicted = torch.max(test_output, 1)[1].data.cpu().numpy().squeeze()\n",
    "labels = lbls[:10].cpu().numpy()\n",
    "print(f\"Predicted number: {predicted}\")\n",
    "print(f\"Actual number:    {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e4f99d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "15f044a653836f064ef67f7c164e60a68a79fea0d9babd44cf8496556a1da232"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
